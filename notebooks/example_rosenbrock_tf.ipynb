{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# We do not need a dataset so we load the fake input\n",
    "from meta_learning.backend.tensorflow.dataset import noop as _dataset_noop\n",
    "\n",
    "# We load the optimizers we care about.\n",
    "from meta_learning.backend.tensorflow import optimizer as _optimizer\n",
    "\n",
    "# The memory types we want to use.\n",
    "from meta_learning.backend.tensorflow import memory as _memory\n",
    "\n",
    "# Our memory requires some gradient implementations\n",
    "from meta_learning.backend.tensorflow import gradient as _gradient\n",
    "\n",
    "\n",
    "# The model we care about.\n",
    "from meta_learning.backend.tensorflow.model import rosenbrock as _model_rosenbrock\n",
    "\n",
    "# We want to save our model as easy as possible.\n",
    "from meta_learning.backend.tensorflow import saver as _saver\n",
    "\n",
    "\n",
    "from meta_learning.plot import rosenbrock as _plot_rosenbrock\n",
    "from meta_learning.plot import utils as _plot_utils\n",
    "\n",
    "from tf_utils import summaries as _summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBALS = {}\n",
    "\n",
    "# Some global variables for this notebook.\n",
    "LOGS_DIR = '../logs'\n",
    "PLOTS_DIR = '../plots'\n",
    "\n",
    "MODEL_DIR_META = os.path.join(LOGS_DIR, 'example_rosenbrock/meta_sgd')\n",
    "MODEL_DIR_SGD = os.path.join(LOGS_DIR, 'example_rosenbrock/sgd')\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "MEM_LEARNING_RATE = 0.001\n",
    "CLIP_GRAD = 10 \n",
    "STEPS_PER_TRAIN_CALL = 100\n",
    "LM_SCALE = 0.5\n",
    "NUM_CENTERS = 100\n",
    "\n",
    "def model_dir_iteration(model_dir, iteration):\n",
    "    return os.path.join(model_dir, str(iteration))\n",
    "\n",
    "def clean_model_dir(model_dir):\n",
    "    if os.path.exists(model_dir):\n",
    "        shutil.rmtree(model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example training loop.\n",
    "def train(model_dir, optimizer_fn, saver_fn):\n",
    "    model = _model_rosenbrock.Rosenbrock(model_dir=model_dir,\n",
    "                                         joined=False,\n",
    "                                         trainable=None) # Trainable only matters if we want to optimize only one dim.\n",
    "    model_fn = model.create_model_fn(optimizer_fn=optimizer_fn, saver_fn=saver_fn)\n",
    "    \n",
    "    estimator = model.create_estimator(model_fn=model_fn)\n",
    "    \n",
    "    dataset = _dataset_noop.Noop(num_epochs=1,\n",
    "                                 batch_size=1,\n",
    "                                 shard_name='train')\n",
    "    \n",
    "    estimator.train(input_fn=dataset.create_input_fn(),\n",
    "                    steps=STEPS_PER_TRAIN_CALL)\n",
    "    \n",
    "    \n",
    "def run(base_model_dir, optimizer_fn, saver_fn):\n",
    "    clean_model_dir(base_model_dir)\n",
    "    model_dir = model_dir_iteration(base_model_dir, 1)\n",
    "    train(model_dir, optimizer_fn, saver_fn)\n",
    "    \n",
    "\n",
    "# Just a easy way to plot the saved data.\n",
    "def plot(base_model_dir):\n",
    "    # We make sure that this is called again\n",
    "    %matplotlib inline  \n",
    "    experiment_results = _summaries.get_summary_save_tensor_dict(base_model_dir, 'rosenbrock')\n",
    "    model_name = os.path.relpath(base_model_dir, LOGS_DIR)\n",
    "    for exp_name, exp_data in sorted(experiment_results.items()):\n",
    "        print('plot ', exp_name)\n",
    "        _plot_rosenbrock.plot_func(PLOTS_DIR, \n",
    "                                   model_name + exp_name, \n",
    "                                   -1.0, 2.0, 100, \n",
    "                                   exp_data['x1'], exp_data['x2'])\n",
    "     \n",
    "    plots = {}\n",
    "    for exp_name, exp_data in sorted(experiment_results.items()):\n",
    "        plots[exp_name] = {'step': exp_data['step'], 'loss':exp_data['loss']}\n",
    "        \n",
    "    _plot_utils.plot_values_by_step(PLOTS_DIR, \n",
    "                            model_name, \n",
    "                            'loss', \n",
    "                            plots, logscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# We need to specify if we want to use the memory with a specificd gradient descent type.\n",
    "# We specify our adam and sgd memory models:\n",
    "\n",
    "meta_sgd_fn = _optimizer.Memory.init_fn(\n",
    "    memory_init_fn=_memory.AdamStatic.init_fn(LEARNING_RATE,\n",
    "                        memory_clip_grad=CLIP_GRAD,\n",
    "                        memory_lm_scale=LM_SCALE,\n",
    "                        memory_num_centers=NUM_CENTERS,\n",
    "                        memory_learning_rate=MEM_LEARNING_RATE),\n",
    "    gradient_init_fn=_gradient.GradientDescent.init_fn(LEARNING_RATE,\n",
    "                                      clip_by_value=CLIP_GRAD))\n",
    "\n",
    "sgd_fn = _optimizer.Reference.init_fn(\n",
    "    gradient_init_fn=_gradient.GradientDescent.init_fn(LEARNING_RATE,\n",
    "                                      clip_by_value=CLIP_GRAD))\n",
    "\n",
    "\n",
    "run(MODEL_DIR_META, \n",
    "    meta_sgd_fn, \n",
    "    _saver.Standard.init_fn())\n",
    "\n",
    "\n",
    "run(MODEL_DIR_SGD, \n",
    "    sgd_fn, \n",
    "    _saver.Standard.init_fn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot(MODEL_DIR_SGD)\n",
    "plot(MODEL_DIR_META)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
